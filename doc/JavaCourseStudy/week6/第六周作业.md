1.（选做）尝试使用 Lambda/Stream/Guava 优化之前作业的代码。

lambda演示demo:
[LambdaDemo.java](../../../src/main/java/com/dhb/gts/javacourse/week6/java8/LambdaDemo.java)
Guava Demo:
[GuavaDemo.java](../../../src/main/java/com/dhb/gts/javacourse/week6/java8/GuavaDemo.java)
Stream Demo:
[StreamDemo.java](../../../src/main/java/com/dhb/gts/javacourse/week6/java8/StreamDemo.java)
[StreamDemo2.java](../../../src/main/java/com/dhb/gts/javacourse/week6/java8/StreamDemo2.java)

2.（选做）尝试使用 Lambda/Stream/Guava 优化工作中编码的代码。

3.（选做）根据课上提供的材料，系统性学习一遍设计模式，并在工作学习中思考如何用设计模式解决问题。

4.（选做）根据课上提供的材料，深入了解 Google 和 Alibaba 编码规范，并根据这些规范，检查自己写代码是否符合规范，有什么可以改进的。

5.（选做）基于课程中的设计原则和最佳实践，分析是否可以将自己负责的业务系统进行数据库设计或是数据库服务器方面的优化

6.（必做）基于电商交易场景（用户、商品、订单），设计一套简单的表结构，提交 DDL 的 SQL 文件到 Github（后面 2 周的作业依然要是用到这个表结构）。

用户信息表：[T_CUSTOMER_INFO.sql](sql/T_CUSTOMER_INFO.sql)
用户登陆状态表：[T_CUSTOMER_LOGIN.sql](sql/T_CUSTOMER_LOGIN.sql)

产品表： [T_PRODUCT_INFO.sql](sql/T_PRODUCT_INFO.sql)

订单汇总表： [T_ORDER_SUMMARY.sql](sql/T_ORDER_SUMMARY.sql)  
订单明细表： [T_ORDER_DETAIL.sql](sql/T_ORDER_DETAIL.sql)

账户余额表：[T_ACCOUNT_BALANCE.sql](sql/T_ACCOUNT_BALANCE.sql)
账户资金流水表：[T_JOURNAL_ACCOUNT.sql](sql/T_JOURNAL_ACCOUNT.sql)


7.（选做）尽可能多的从“常见关系数据库”中列的清单，安装运行，并使用上一题的 SQL 测试简单的增删改查。

通过mysql 结合fluent mybatis 实现insert select ..
[CustomerInfoContraller.java](../../../src/main/java/com/dhb/gts/javacourse/week6/mysqltest/CustomerInfoContraller.java)
通过上述开放的rest接口实现增、删、改、查操作：
增加：
http://127.0.0.1:8084/customerInfo/add?userid=10006&name=%E5%BC%A0%E4%B8%891&mobile=13888888889&email=admin1@test.com&identityNo=320111233456780967&gender=1

删除：
http://127.0.0.1:8084/customerInfo/delete?id=10001

修改：
http://127.0.0.1:8084/customerInfo/modify?id=10000&identityNo=320111233456780988&gender=2

查询：
http://127.0.0.1:8084/customerInfo/query?id=10000

8.（选做）基于上一题，尝试对各个数据库测试 100 万订单数据的增删改查性能。

基于mysql数据库 innoDB存储引擎，插入100万数据：
[RandomInsertOrderTable.java](../../../src/main/java/com/dhb/gts/javacourse/week6/mysqltest/RandomInsertOrderTable.java)
在每批次不同数据量的情况下进行测试：
http://127.0.0.1:8084/randomInsertOrderTable?total=100000&batch=1200
```
2021-09-12 22:51:14.698  INFO 8532 --- [nio-8084-exec-7] c.d.g.j.w.m.RandomInsertOrderTable       : 总计插入批次共84次，其中，最大耗时:947ms 最小耗时：372ms 平均耗时:521.1190476190476ms
2021-09-12 22:51:14.698  INFO 8532 --- [nio-8084-exec-7] c.d.g.j.w.m.RandomInsertOrderTable       : 批量插入数据 totalSize [100000]... 共耗时[43793] ms
```
http://127.0.0.1:8084/randomInsertOrderTable?total=100000&batch=1000
```
2021-09-12 22:46:52.265  INFO 8532 --- [nio-8084-exec-1] c.d.g.j.w.m.RandomInsertOrderTable       : 总计插入批次共101次，其中，最大耗时:1039ms 最小耗时：309ms 平均耗时:432.019801980198ms
2021-09-12 22:46:52.265  INFO 8532 --- [nio-8084-exec-1] c.d.g.j.w.m.RandomInsertOrderTable       : 批量插入数据 totalSize [100000]... 共耗时[43694] ms
```
http://127.0.0.1:8084/randomInsertOrderTable?total=100000&batch=800
```
2021-09-12 22:48:25.810  INFO 8532 --- [nio-8084-exec-8] c.d.g.j.w.m.RandomInsertOrderTable       : 总计插入批次共126次，其中，最大耗时:1009ms 最小耗时：243ms 平均耗时:395.6746031746032ms
2021-09-12 22:48:25.810  INFO 8532 --- [nio-8084-exec-8] c.d.g.j.w.m.RandomInsertOrderTable       : 批量插入数据 totalSize [100000]... 共耗时[49914] ms
```
http://127.0.0.1:8084/randomInsertOrderTable?total=100000&batch=600
```
2021-09-12 22:49:57.453  INFO 8532 --- [nio-8084-exec-5] c.d.g.j.w.m.RandomInsertOrderTable       : 总计插入批次共167次，其中，最大耗时:724ms 最小耗时：199ms 平均耗时:348.19161676646706ms
2021-09-12 22:49:57.453  INFO 8532 --- [nio-8084-exec-5] c.d.g.j.w.m.RandomInsertOrderTable       : 批量插入数据 totalSize [100000]... 共耗时[58201] ms
```
可以看到，当每个批次数据量大概为1000的时候，单线程批次插入数据的效率达到最优。

在公司测试，不用vpn，网络环境要优化不少：
```
2021-09-13 14:03:41.375  INFO 13360 --- [nio-8084-exec-1] c.d.g.j.w.m.RandomInsertOrderTable       : 总计插入批次共101次，其中，最大耗时:351ms 最小耗时：173ms 平均耗时:244.04950495049505ms
2021-09-13 14:03:41.375  INFO 13360 --- [nio-8084-exec-1] c.d.g.j.w.m.RandomInsertOrderTable       : 批量插入数据 totalSize [100000]... 共耗时[24676] ms
```
批次改为1200
```
2021-09-13 14:05:13.146  INFO 13360 --- [nio-8084-exec-4] c.d.g.j.w.m.RandomInsertOrderTable       : 总计插入批次共84次，其中，最大耗时:630ms 最小耗时：235ms 平均耗时:306.6547619047619ms
2021-09-13 14:05:13.146  INFO 13360 --- [nio-8084-exec-4] c.d.g.j.w.m.RandomInsertOrderTable       : 批量插入数据 totalSize [100000]... 共耗时[25774] ms
```
批次改为800
```
2021-09-13 14:06:23.440  INFO 13360 --- [nio-8084-exec-6] c.d.g.j.w.m.RandomInsertOrderTable       : 总计插入批次共126次，其中，最大耗时:560ms 最小耗时：164ms 平均耗时:227.0793650793651ms
2021-09-13 14:06:23.441  INFO 13360 --- [nio-8084-exec-6] c.d.g.j.w.m.RandomInsertOrderTable       : 批量插入数据 totalSize [100000]... 共耗时[28637] ms
```
当数据量达到100万时，对数据进行查询：
[QueryOrderTable.java](../../../src/main/java/com/dhb/gts/javacourse/week6/mysqltest/QueryOrderTable.java)

http://127.0.0.1:8084/queryByKey?key=100033
```
通过key查询，走索引耗时：2.762 ms
通过key查询，走索引耗时：2.870 ms
```
http://127.0.0.1:8084/queryByOther?orderNo=100787 
不走索引，当查询的都是全新的数据的时候，mysql中也没有缓存，此时可以看到几乎到秒级。
```
不通过key查询，全表扫描耗时：1.807 s
不通过key查询，全表扫描耗时：1.569 s
```
如果查询的是重复的数据，第二次查询该数据，此时的查询会走缓存，优化到毫秒级别：
```
不通过key查询，全表扫描耗时：2.566 ms
不通过key查询，全表扫描耗时：1.876 ms
```

9.（选做）尝试对 MySQL 不同引擎下测试 100 万订单数据的增删改查性能。

10.（选做）模拟 1000 万订单数据，测试不同方式下导入导出（数据备份还原）MySQL 的速度，包括 jdbc 程序处理和命令行处理。思考和实践，如何提升处理效率。

11.（选做）对 MySQL 配置不同的数据库连接池（DBCP、C3P0、Druid、Hikari），测试增删改查 100 万次，对比性能，生成报告。

[不同的数据库连接池（DBCP、C3P0、Druid、Hikari）下对mysql增删改查的性能对比](不同的数据库连接池（DBCP、C3P0、Druid、Hikari）下对mysql增删改查的性能对比.md)

[不同的数据库连接池（DBCP、C3P0、Druid、Hikari）下对mysql增删改查的性能对比(二)](不同的数据库连接池（DBCP、C3P0、Druid、Hikari）下对mysql增删改查的性能对比%28二%29.md)