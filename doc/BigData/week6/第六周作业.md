# 作业一：使用 RDD API 实现带词频的倒排索引
倒排索引（Inverted index），也被称为反向索引。它是文档检索系统中最常用的数据结构。被广泛地应用于全文搜索引擎。

例子如下，被索引的文件为（0，1，2 代表文件名）
```
“it is what it is”
“what is it”
“it is a banana”
```
我们就能得到下面的反向文件索引：
```
“a”: {2}
“banana”: {2}
“is”: {0, 1, 2}
“it”: {0, 1, 2}
“what”: {0, 1}
再加上词频为：
“a”: {(2,1)}
“banana”: {(2,1)}
“is”: {(0,2), (1,1), (2,1)}
“it”: {(0,2), (1,1), (2,1)}
“what”: {(0,1), (1,1)}`
```

第一题解答：
[第一题解题过程](第一题解题过程.md)

# 作业二：Distcp 的 Spark 实现
使用 Spark 实现 Hadoop 分布式数据传输工具 DistCp (distributed copy)，只要求实现最基础的 copy 功能，对于 -update、-diff、-p 不做要求。

对于 HadoopDistCp 的功能与实现，可以参考：

https://hadoop.apache.org/docs/current/hadoop-distcp/DistCp.html

https://github.com/apache/hadoop/tree/release-2.7.1/hadoop-tools/hadoop-distcp

Hadoop 使用 MapReduce 框架来实现分布式 copy，在 Spark 中应使用 RDD 来实现分布式 copy，应实现的功能为：

sparkDistCp hdfs://xxx/source hdfs://xxx/target

得到的结果为：

启动多个 task/executor，将 hdfs://xxx/source 目录复制到 hdfs://xxx/target，得到 hdfs://xxx/target/source
需要支持 source 下存在多级子目录
需支持 -i Ignore failures 参数
需支持 -m max concurrence 参数，控制同时 copy 的最大并发 task 数
作业说明
两个题目都要做
先在本地（个人电脑）进行程序编写和测试

测试方法：

下载 Spark 包并解压： https://www.apache.org/dyn/closer.lua/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz
通过 bin/spark-shell 启动交互式 shell 进行测试
提交的代码要自行打包成 jar 包（非 fat jar），利用 bin/spark-submit 进行

第二题解答：
[第二题解题过程](第二题解题过程.md)