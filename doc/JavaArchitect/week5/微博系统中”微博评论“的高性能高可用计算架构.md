
# 1.性能估算

## 1.1 用户量预估:
根据第六课
2020.9月月活5.11亿，日活2.24亿（参考《微博2020用户发展报告》）。

## 1.2 关键行为:
1. 发微博；
2. 看微博；
3. 评论微博。

## 1.3 性能估算
微博的评论是微博最主要的互动功能之一，大部分大V及明星的微博都会被评论。而普通人的微博也会不断的被评论。
查看微博的人中，假定存在一半的人都会进行评论，参考看微博的数据：
由于绝大部分微博用户看微博的对象是大V和明星，因此我们假设平均一条微博观看人数有100次，则观看微博的次数为：
2.5亿* 100 = 250亿。
那么评论微博的人的数量，按二八原则，百分之二十的用户会进行评论，大约为看微博人数的 1/4，按约为60亿。
大部分评论微博的行为和看微博、发微博的行为都会集中在高峰的4小时内。
因此计算如下：
60亿*60%/(4/3600) = 40k/s

# 2.业务特点分析
评论微博也是一个典型的写操作，因此同样不能用缓存，可以用负载均衡。

# 3.架构分析
用户量过亿，应该要用多级负载均衡架构，覆盖DNS -> F5 -> Nginx -> 网关的多级负载均衡。

# 4.架构设计
## 4.1 负载均衡算法选择
发微博的时候依赖登录状态，登录状态一般都是保存在分布式缓存中的，因此发微博的时候，将请求发送给任意服务器都可以，
但是在评论微博的时候，评论之后的数据会在查看微博的时候一同关联查询，因此评论微博的数据，应该按照被评论的微博账号尽量的内聚。
尽量把对同一个ID的评论数据内聚到同一个节点，以降低数据合并的时间。因此负载均衡算法最好选择hash。

## 4.2 业务服务器数量估算
评论微博的单次评论的数据相对较小，因此写入过程会比发微博的数据理论上更快。
发微博评论也会涉及几个关键的处理：内容审核（依赖审核系统）、数据写入存储（依赖存储系统）、数据写入缓存（依赖缓存系统），因
此按照一个服务每秒处理按1000来估算，完成40K/s的TPS，需要40台服务器，加上一定的预留量，50台服务器差不多了。

![发微博评论的多级负载均衡架构](发微博评论的多级负载均衡架构.png)
